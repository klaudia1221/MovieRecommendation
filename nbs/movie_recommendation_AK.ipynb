{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fast.ai GENERATE ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies: 53889 Number of users: 283228\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular import *\n",
    "\n",
    "\n",
    "#'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "#path = untar_data(URLs.ML_SAMPLE)\n",
    "#print(path.ls())\n",
    "\n",
    "ratings = pd.read_csv('../../moviebook_data/ml-latest/ratings.csv')\n",
    "all_movies =  ratings['movieId'].unique().astype(str)\n",
    "all_movies_df = DataFrame(all_movies,columns=['movieId'])\n",
    "all_users = ratings['userId'].unique().astype(str)\n",
    "all_users_df = DataFrame(all_movies,columns=['userId'])\n",
    "\n",
    "# save index to use as alternative\n",
    "all_movies_df.index.name = 'movie_ix'\n",
    "all_movies_df.to_csv('../data/movies_id.csv')\n",
    "\n",
    "print('Number of movies:', len(all_movies),'Number of users:', len(all_users))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53889"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user,title,rating = 'userId','movieId','rating'\n",
    "data = CollabDataBunch.from_df(ratings, seed=42, valid_pct=0, item_name=title)\n",
    "\n",
    "#data = CollabList.from_df(ratings, cat_names=[user,title], procs=Categorify)\n",
    "#data_split = data.split_by_rand_pct(valid_pct=0.2, seed=200).label_from_df(cols=rating)\n",
    "#print('classes: ', len(data_split.x.classes['movieId']))\n",
    "#il = data.split_by_rand_pct(valid_pct=0, seed=200)\n",
    "#data_split = il.label_from_df(cols=rating)\n",
    "#len(data_split.train.x.classes['movieId'])\n",
    "#data_bunch = data_split.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingDotBias(\n",
       "  (u_weight): Embedding(283229, 40)\n",
       "  (i_weight): Embedding(53890, 40)\n",
       "  (u_bias): Embedding(283229, 1)\n",
       "  (i_bias): Embedding(53890, 1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_range = [0,5.5]\n",
    "#y_range_value = (y_range[1]-y_range[0])+\n",
    "learn = collab_learner(data, n_factors=40, y_range=y_range, wd=1e-1)\n",
    "\n",
    "#print(len(learn.data.x.classes['movieId']))\n",
    "#print(learn.data.get_emb_szs())\n",
    "#print(learn.weight(all_movies,is_item=True).shape)\n",
    "#print(learn.bias(all_movies,is_item=True).shape)\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARN - NOT REQUIRED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ebd3a191e924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskip_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\train.py\u001b[0m in \u001b[0;36mlr_find\u001b[1;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=False, clip:float=None,\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastprogress\\fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='433647', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c1ed9d459fcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[0;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[0;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastprogress\\fastprogress.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_update\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\fastai\\basic_data.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;34m\"Process and returns items from `DataLoader`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproc_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                 \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m                 \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\PUBLIC\\Anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:17 <p><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.355649</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.399756</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.432609</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487330</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.489273</td>\n",
       "      <td></td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.473474</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.455817</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.421054</td>\n",
       "      <td></td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.378137</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.337703</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.279437</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.231384</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.193775</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.172068</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.151167</td>\n",
       "      <td></td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(15, 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('-4');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go forward function\n",
    "\n",
    "Tutaj jest załadowane i obliczane wagi do funkcji, a takżę matrix\n",
    "Na wyjściu do zapisania\n",
    "- `movies_weights`\n",
    "- `movies_bias`\n",
    "- `user_weights`\n",
    "- `user_bias`\n",
    "- `matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9724, 41]) torch.Size([610, 41])\n",
      "torch.Size([610, 9724])\n"
     ]
    }
   ],
   "source": [
    "# learn.model.cuda()\n",
    "movies_weights = learn.weight(all_movies,is_item=True)\n",
    "movies_bias = torch.t(learn.bias(all_movies,is_item=True)[None])\n",
    "movies_f = torch.cat([movies_bias, movies_weights],1)\n",
    "\n",
    "user_weights = learn.weight(all_users,is_item=False)\n",
    "user_bias = torch.t(learn.bias(all_users,is_item=False)[None])\n",
    "user_f = torch.cat([user_weights, user_bias],1)\n",
    "\n",
    "\n",
    "matrix=user_f@torch.t(movies_f)\n",
    "\n",
    "print(movies_f.shape,user_f.shape)\n",
    "print(matrix.shape)\n",
    "\n",
    "#learn.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_ix:  0 movie_ix:  34\n",
      "    userId  movieId  rating  timestamp\n",
      "34       1      593     4.0  964983793\n",
      "(FloatItem 4.310879, tensor(4.3109), tensor(4.3109))\n",
      "tensor([4.3109], device='cuda:0')\n",
      "sum_weights: tensor(0.2232)  with bias: tensor([1.2879]) sigmoid: tensor([0.7838]) result: tensor([4.3109])\n",
      "\n",
      "\n",
      "user_ix:  0 movie_ix:  35\n",
      "    userId  movieId  rating  timestamp\n",
      "35       1      596     5.0  964982838\n",
      "(FloatItem 4.646312, tensor(4.6463), tensor(4.6463))\n",
      "tensor([4.6463], device='cuda:0')\n",
      "sum_weights: tensor(0.8953)  with bias: tensor([1.6943]) sigmoid: tensor([0.8448]) result: tensor([4.6463])\n",
      "\n",
      "\n",
      "user_ix:  1 movie_ix:  34\n",
      "Empty DataFrame\n",
      "Columns: [userId, movieId, rating, timestamp]\n",
      "Index: []\n",
      "(FloatItem 3.9020193, tensor(3.9020), tensor(3.9020))\n",
      "tensor([3.9020], device='cuda:0')\n",
      "sum_weights: tensor(0.3560)  with bias: tensor([0.8928]) sigmoid: tensor([0.7095]) result: tensor([3.9020])\n",
      "\n",
      "\n",
      "user_ix:  1 movie_ix:  35\n",
      "Empty DataFrame\n",
      "Columns: [userId, movieId, rating, timestamp]\n",
      "Index: []\n",
      "(FloatItem 3.3712225, tensor(3.3712), tensor(3.3712))\n",
      "tensor([3.3712], device='cuda:0')\n",
      "sum_weights: tensor(0.1887)  with bias: tensor([0.4597]) sigmoid: tensor([0.6129]) result: tensor([3.3712])\n",
      "\n",
      "\n",
      "user_ix:  2 movie_ix:  34\n",
      "Empty DataFrame\n",
      "Columns: [userId, movieId, rating, timestamp]\n",
      "Index: []\n",
      "(FloatItem 1.0854188, tensor(1.0854), tensor(1.0854))\n",
      "tensor([1.0854], device='cuda:0')\n",
      "sum_weights: tensor(-1.7300)  with bias: tensor([-1.4029]) sigmoid: tensor([0.1973]) result: tensor([1.0854])\n",
      "\n",
      "\n",
      "user_ix:  2 movie_ix:  35\n",
      "Empty DataFrame\n",
      "Columns: [userId, movieId, rating, timestamp]\n",
      "Index: []\n",
      "(FloatItem 1.3866374, tensor(1.3866), tensor(1.3866))\n",
      "tensor([1.3866], device='cuda:0')\n",
      "sum_weights: tensor(-1.1486)  with bias: tensor([-1.0874]) sigmoid: tensor([0.2521]) result: tensor([1.3866])\n"
     ]
    }
   ],
   "source": [
    "#%%debug\n",
    "\n",
    "movie_ix = 34\n",
    "user_ix = 0\n",
    "\n",
    "def predict_single(movie_ix,user_ix):\n",
    "    sum1 = (user_weights[user_ix]*movies_weights[movie_ix]).sum();\n",
    "    sum2 = sum1+user_bias[user_ix]+movies_bias[movie_ix];\n",
    "    sigm = torch.sigmoid(sum2)\n",
    "    print('sum_weights:', sum1, ' with bias:', sum2, 'sigmoid:',sigm, 'result:', sigm*(y_range[1]-y_range[0])+y_range[0]);\n",
    "    \n",
    "\n",
    "def show_predicts(movie_ix,user_ix):\n",
    "    movie_id =  int(all_movies[movie_ix])\n",
    "    user_id = int(all_users[user_ix])\n",
    "\n",
    "    #learn.model.cuda()\n",
    "\n",
    "\n",
    "    movie_t = learn.get_idx([str(movie_id)],is_item=True).cuda() # torch.LongTensor([movie_ix+1]).cuda()   #n&a is first element\n",
    "    user_t =  learn.get_idx([str(user_id)],is_item=False).cuda() # torch.LongTensor([user_ix+1]).cuda()   #n&a is first element\n",
    "    \n",
    "    \n",
    "    # print(movie_id,movie_t,user_id ,user_t)\n",
    "    print('user_ix: ', user_ix, 'movie_ix: ', movie_ix)\n",
    "    print(ratings[(ratings['movieId']==movie_id) & (ratings['userId']==user_id)]); # real rating\n",
    "    \n",
    "    learn.model.cuda()\n",
    "    print(learn.predict({'userId': user_id, 'movieId': movie_id }))  #using predict function\n",
    "    print(learn.model.forward(user_t,movie_t)) #using forward function\n",
    "    \n",
    "    predict_single(movie_ix,user_ix)\n",
    "    \n",
    "    \n",
    "\n",
    "show_predicts(movie_ix,user_ix)\n",
    "print('\\n')\n",
    "show_predicts(movie_ix+1,user_ix)\n",
    "print('\\n')\n",
    "show_predicts(movie_ix,user_ix+1)\n",
    "print('\\n')\n",
    "show_predicts(movie_ix+1,user_ix+1)\n",
    "print('\\n')\n",
    "show_predicts(movie_ix,user_ix+2)\n",
    "print('\\n')\n",
    "show_predicts(movie_ix+1,user_ix+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3109, 4.6463],\n",
       "        [3.9020, 3.3712],\n",
       "        [1.0854, 1.3866]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show_predicts(movie_ix,user_ix)\n",
    "\n",
    "users_w = user_weights[[user_ix,user_ix+1,user_ix+2]]\n",
    "users_b = user_bias[[user_ix,user_ix+1,user_ix+2]]\n",
    "\n",
    "movies_w = movies_weights[[movie_ix,movie_ix+1]]\n",
    "movies_b =  movies_bias[[movie_ix,movie_ix+1]]\n",
    "\n",
    "def forward(users_w,users_b,movies_w,movies_b):\n",
    "    #print(users_w.shape,movies_w.shape)\n",
    "    dot = ((users_w@torch.t(movies_w)+users_b).squeeze()+torch.t(movies_b)).squeeze()\n",
    "    res = torch.sigmoid(dot)*(y_range[1]-y_range[0])+y_range[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "forward(users_w,users_b,movies_w,movies_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([610, 9724])\n"
     ]
    }
   ],
   "source": [
    "matrix = forward(user_weights,user_bias,movies_weights,movies_bias)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/movie_recommendation.pickle', 'wb') as handle: #24 megabytes, without matrix 1.6MB\n",
    "    pickle.dump(\n",
    "        (matrix,\n",
    "         movies_weights,\n",
    "         movies_bias,\n",
    "         user_weights,\n",
    "         user_bias), handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA (categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na wyniku dostajemy zawsze movies i jeśli je łączym to trzeba wiedzieć że je łączymy po `movie_ix`. Nie zawsze w `movies_input.zip` będą wszystkie filmy które były w modelu. Ale w modelu powinny być wszystkie wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>movie_ix</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>genres</th>\n",
       "      <th>cover</th>\n",
       "      <th>title</th>\n",
       "      <th>full-title</th>\n",
       "      <th>year</th>\n",
       "      <th>director</th>\n",
       "      <th>producer</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>rating</th>\n",
       "      <th>small-cover</th>\n",
       "      <th>plot</th>\n",
       "      <th>length</th>\n",
       "      <th>youtubeId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8648</th>\n",
       "      <td>118082</td>\n",
       "      <td>9692</td>\n",
       "      <td>1567437</td>\n",
       "      <td>244458.0</td>\n",
       "      <td>Comedy,Crime,Thriller</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTQ2NT...</td>\n",
       "      <td>The Voices</td>\n",
       "      <td>The Voices (2014)</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Marjane Satrapi</td>\n",
       "      <td>1984 Private Defense Contractors</td>\n",
       "      <td>http://www.imdb.com/title/tt1567437/</td>\n",
       "      <td>6.4</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTQ2NT...</td>\n",
       "      <td>Jerry (Ryan Reynolds) is that chipper guy cloc...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3hQpV9Q0A7E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>129313</td>\n",
       "      <td>9694</td>\n",
       "      <td>2392672</td>\n",
       "      <td>179150.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTcyND...</td>\n",
       "      <td>Reality</td>\n",
       "      <td>Reality (2014)</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Quentin Dupieux</td>\n",
       "      <td>Realitism Films</td>\n",
       "      <td>http://www.imdb.com/title/tt2392672/</td>\n",
       "      <td>6.9</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMTcyND...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>roXp_BwRjmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8650</th>\n",
       "      <td>130050</td>\n",
       "      <td>9695</td>\n",
       "      <td>1991031</td>\n",
       "      <td>279972.0</td>\n",
       "      <td>Drama,Fantasy,Horror,Mystery,Thriller</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjM3ND...</td>\n",
       "      <td>Digging Up the Marrow</td>\n",
       "      <td>Digging Up the Marrow (2014)</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Adam Green</td>\n",
       "      <td>ArieScope Pictures</td>\n",
       "      <td>http://www.imdb.com/title/tt1991031/</td>\n",
       "      <td>5.8</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjM3ND...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>MCSYNT7Xrfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8651</th>\n",
       "      <td>130052</td>\n",
       "      <td>9696</td>\n",
       "      <td>1780798</td>\n",
       "      <td>112454.0</td>\n",
       "      <td>Drama,Horror</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYWNkYm...</td>\n",
       "      <td>Clown</td>\n",
       "      <td>Clown (2014)</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Jon Watts</td>\n",
       "      <td>Cross Creek Pictures</td>\n",
       "      <td>http://www.imdb.com/title/tt1780798/</td>\n",
       "      <td>5.7</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BYWNkYm...</td>\n",
       "      <td>A little boy's birthday party gets ruined when...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>utmvmr7cgcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8652</th>\n",
       "      <td>130840</td>\n",
       "      <td>9697</td>\n",
       "      <td>3395184</td>\n",
       "      <td>241855.0</td>\n",
       "      <td>Horror,Romance,Sci-Fi</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjMwNz...</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Spring (2014)</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Justin Benson</td>\n",
       "      <td>Rustic Films</td>\n",
       "      <td>http://www.imdb.com/title/tt3395184/</td>\n",
       "      <td>6.7</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjMwNz...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>gcoRtZkDwKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId  movie_ix   imdbId    tmdbId  \\\n",
       "8648   118082      9692  1567437  244458.0   \n",
       "8649   129313      9694  2392672  179150.0   \n",
       "8650   130050      9695  1991031  279972.0   \n",
       "8651   130052      9696  1780798  112454.0   \n",
       "8652   130840      9697  3395184  241855.0   \n",
       "\n",
       "                                     genres  \\\n",
       "8648                  Comedy,Crime,Thriller   \n",
       "8649                                 Comedy   \n",
       "8650  Drama,Fantasy,Horror,Mystery,Thriller   \n",
       "8651                           Drama,Horror   \n",
       "8652                  Horror,Romance,Sci-Fi   \n",
       "\n",
       "                                                  cover  \\\n",
       "8648  https://m.media-amazon.com/images/M/MV5BMTQ2NT...   \n",
       "8649  https://m.media-amazon.com/images/M/MV5BMTcyND...   \n",
       "8650  https://m.media-amazon.com/images/M/MV5BMjM3ND...   \n",
       "8651  https://m.media-amazon.com/images/M/MV5BYWNkYm...   \n",
       "8652  https://m.media-amazon.com/images/M/MV5BMjMwNz...   \n",
       "\n",
       "                      title                    full-title    year  \\\n",
       "8648             The Voices             The Voices (2014)  2014.0   \n",
       "8649                Reality                Reality (2014)  2014.0   \n",
       "8650  Digging Up the Marrow  Digging Up the Marrow (2014)  2014.0   \n",
       "8651                  Clown                  Clown (2014)  2014.0   \n",
       "8652                 Spring                 Spring (2014)  2014.0   \n",
       "\n",
       "             director                          producer  \\\n",
       "8648  Marjane Satrapi  1984 Private Defense Contractors   \n",
       "8649  Quentin Dupieux                   Realitism Films   \n",
       "8650       Adam Green                ArieScope Pictures   \n",
       "8651        Jon Watts              Cross Creek Pictures   \n",
       "8652    Justin Benson                      Rustic Films   \n",
       "\n",
       "                                  imdb_url  rating  \\\n",
       "8648  http://www.imdb.com/title/tt1567437/     6.4   \n",
       "8649  http://www.imdb.com/title/tt2392672/     6.9   \n",
       "8650  http://www.imdb.com/title/tt1991031/     5.8   \n",
       "8651  http://www.imdb.com/title/tt1780798/     5.7   \n",
       "8652  http://www.imdb.com/title/tt3395184/     6.7   \n",
       "\n",
       "                                            small-cover  \\\n",
       "8648  https://m.media-amazon.com/images/M/MV5BMTQ2NT...   \n",
       "8649  https://m.media-amazon.com/images/M/MV5BMTcyND...   \n",
       "8650  https://m.media-amazon.com/images/M/MV5BMjM3ND...   \n",
       "8651  https://m.media-amazon.com/images/M/MV5BYWNkYm...   \n",
       "8652  https://m.media-amazon.com/images/M/MV5BMjMwNz...   \n",
       "\n",
       "                                                   plot  length    youtubeId  \n",
       "8648  Jerry (Ryan Reynolds) is that chipper guy cloc...   103.0  3hQpV9Q0A7E  \n",
       "8649                                                NaN    95.0  roXp_BwRjmY  \n",
       "8650                                                NaN    89.0  MCSYNT7Xrfs  \n",
       "8651  A little boy's birthday party gets ruined when...   100.0  utmvmr7cgcg  \n",
       "8652                                                NaN   109.0  gcoRtZkDwKA  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('../data/movie_input.csv');\n",
    "movies_id = pd.read_csv('../data/movies_id.csv');\n",
    "\n",
    "#movies['movie_ix']\n",
    "movies.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9724, 40]) torch.Size([9724, 1])\n",
      "movies_pca.shape: torch.Size([10, 9724])\n"
     ]
    }
   ],
   "source": [
    "print(movies_weights.shape,movies_bias.shape) #9724 movies\n",
    "movies_factors = torch.cat([movies_weights,movies_bias],1)\n",
    "movies_pca = torch.t(movies_factors.pca(10))\n",
    "\n",
    "print('movies_pca.shape:', movies_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor(0.4408), 'Peggy Sue Got Married', 2469),\n",
       " (tensor(0.4392), 'How to Make an American Quilt', 46),\n",
       " (tensor(0.4338), 'Cowboy Bebop: The Movie', 6283),\n",
       " (tensor(0.3992), 'Mulholland Falls', 707),\n",
       " (tensor(0.3973), 'The Last Airbender', 78893),\n",
       " (tensor(0.3898), 'Dark City', 1748),\n",
       " (tensor(0.3764), 'The World Is Not Enough', 3082),\n",
       " (tensor(0.3757), 'Little Big Man', 3037),\n",
       " (tensor(0.3745), 'History of the World: Part I', 2301),\n",
       " (tensor(0.3741), 'Operation Petticoat', 4802),\n",
       " (tensor(-0.4859), 'The Ladykillers', 7367),\n",
       " (tensor(-0.4744), 'Panic Room', 5266),\n",
       " (tensor(-0.4700), 'The Blair Witch Project', 2710),\n",
       " (tensor(-0.4303), 'Toy Story', 1),\n",
       " (tensor(-0.4271), 'The Age of Innocence', 412),\n",
       " (tensor(-0.4175), \"It's Kind of a Funny Story\", 80693),\n",
       " (tensor(-0.4151), 'The Piano', 509),\n",
       " (tensor(-0.4086), 'Rebel Without a Cause', 1103),\n",
       " (tensor(-0.4058), 'Scream', 1407),\n",
       " (tensor(-0.4033), 'Meet the Parents', 3948)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_fac0 = [(f, i,id) for f,i,id in zip(\n",
    "    movies_pca[7, movies['movie_ix']], # tylko przefiltrowane movies po id z uczenia.\n",
    "    movies['title'], \n",
    "    movies['movieId'])]\n",
    "[ \n",
    "    *sorted(movies_fac0, key=itemgetter(0), reverse=True)[:10],\n",
    "    *sorted(movies_fac0, key=itemgetter(0))[:10]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 10)\n"
     ]
    }
   ],
   "source": [
    "movies_pca_cpu = torch.t(movies_pca).cpu().detach().numpy()\n",
    "print(movies_pca_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724,) (8653,)\n",
      "   movieId  movie_ix               title  category\n",
      "0        1         0           Toy Story         4\n",
      "1        3         1    Grumpier Old Men         4\n",
      "2        6         2                Heat         2\n",
      "3       47         3               Se7en         2\n",
      "4       50         4  The Usual Suspects         2\n",
      "   movie_ix  movieId  category\n",
      "0         0        1         4\n",
      "1         1        3         4\n",
      "2         2        6         2\n",
      "3         3       47         2\n",
      "4         4       50         2\n",
      "CPU times: user 1.61 s, sys: 0 ns, total: 1.61 s\n",
      "Wall time: 406 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Importing Modules\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Declaring Model\n",
    "model = KMeans(n_clusters=5)\n",
    "\n",
    "# Fitting Model\n",
    "model.fit(movies_pca_cpu)\n",
    "\n",
    "# Prediction on the entire data\n",
    "all_predictions = model.predict(movies_pca_cpu)\n",
    "\n",
    "# Printing Predictions\n",
    "print(all_predictions.shape, all_predictions[movies['movie_ix']].shape)\n",
    "\n",
    "movies['category'] = all_predictions[movies['movie_ix']]\n",
    "movies_id['category'] = all_predictions[movies_id['movie_ix']]\n",
    "print(movies[['movieId','movie_ix','title','category']].head())\n",
    "\n",
    "movies_id.to_csv('../data/movies_category.csv',index=False)\n",
    "print(movies_id.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'Blown Away', 423),\n",
       " (4, 'Space Jam', 673),\n",
       " (4, \"Pete's Dragon\", 1030),\n",
       " (4, \"McHale's Navy\", 1445),\n",
       " (4, 'Con Air', 1552),\n",
       " (4, 'I Know What You Did Last Summer', 1644),\n",
       " (4, 'Toys', 2253),\n",
       " (4, 'I Still Know What You Did Last Summer', 2338),\n",
       " (4, 'Psycho', 2389),\n",
       " (4, 'Howard the Duck', 2450),\n",
       " (0, 'From Dusk Till Dawn', 70),\n",
       " (0, 'Canadian Bacon', 157),\n",
       " (0, 'Billy Madison', 216),\n",
       " (0, 'The Mask', 367),\n",
       " (0, \"She's the One\", 804),\n",
       " (0, 'Escape to Witch Mountain', 1009),\n",
       " (0, 'The Three Caballeros', 1024),\n",
       " (0, 'That Thing You Do!', 1042),\n",
       " (0, 'Batman Returns', 1377),\n",
       " (0, 'Best Men', 1473)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_fac0 = [(f, i,id) for f,i,id in zip(all_predictions[movies['movie_ix']], \n",
    "                                           movies['title'],\n",
    "                                           movies['movieId'])]\n",
    "[ \n",
    "    *sorted(movies_fac0, key=itemgetter(0), reverse=True)[:10],\n",
    "    *sorted(movies_fac0, key=itemgetter(0))[:10]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_movies_cold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3583\n",
       "3    1817\n",
       "1    1537\n",
       "4     944\n",
       "2     772\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv('../data/movie_input.csv');\n",
    "movies.index = movies['movie_ix']\n",
    "\n",
    "movies['category'].value_counts() # each category and values connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size of each category:\n",
      "\n",
      "Sample  0 :  5\n",
      "487     Ace Ventura: When Nature Calls\n",
      "266      Star Trek: The Motion Picture\n",
      "1683           Pee-wee's Big Adventure\n",
      "654          Robin Hood: Men in Tights\n",
      "1584                     Arachnophobia\n",
      "Name: title, dtype: object\n",
      "\n",
      "Sample  1 :  5\n",
      "1262                  Hancock\n",
      "846           Die Another Day\n",
      "1357    Beverly Hills Cop III\n",
      "3510      Weekend at Bernie's\n",
      "987               Deep Impact\n",
      "Name: title, dtype: object\n",
      "\n",
      "Sample  2 :  5\n",
      "387                                     Life Is Beautiful\n",
      "28                                       Schindler's List\n",
      "717     Dr. Strangelove or: How I Learned to Stop Worr...\n",
      "1020                                               Aliens\n",
      "1104                                               Amélie\n",
      "Name: title, dtype: object\n",
      "\n",
      "Sample  3 :  5\n",
      "380                 The Jerk\n",
      "579     Natural Born Killers\n",
      "198               Spaceballs\n",
      "1514        The Dark Crystal\n",
      "1978                Coraline\n",
      "Name: title, dtype: object\n",
      "\n",
      "Sample  4 :  5\n",
      "768                                 The Last Samurai\n",
      "747                                   Ocean's Eleven\n",
      "831                          The Godfather: Part III\n",
      "1877    Harry Potter and the Deathly Hallows: Part 1\n",
      "1869                        How to Train Your Dragon\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def get_sample(cat, n=5,head=100, min_cnt=20):\n",
    "    return movies[(movies['category']==cat) & (movies['cnt']>min_cnt) ].sort_values(by='rating',ascending=False).head(head).sample(n)\n",
    "\n",
    "print('sample size of each category:')\n",
    "\n",
    "for i in range(5):\n",
    "    s = get_sample(i,5)\n",
    "    print('\\nSample ',i,': ', len(s))\n",
    "    print(s['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 The Jewel of the Nile\n",
       "1                                         The Rocketeer\n",
       "2                        How the Grinch Stole Christmas\n",
       "3                                        101 Dalmatians\n",
       "4                                            Milk Money\n",
       "5                                           Van Helsing\n",
       "6                                            Disclosure\n",
       "7                    National Treasure: Book of Secrets\n",
       "8                                                  Hulk\n",
       "9                                     Final Destination\n",
       "10                           Terminator 2: Judgment Day\n",
       "11                The Lord of the Rings: The Two Towers\n",
       "12    Dr. Strangelove or: How I Learned to Stop Worr...\n",
       "13           Star Wars: Episode VI - Return of the Jedi\n",
       "14                                   Back to the Future\n",
       "15                                      Good Bye Lenin!\n",
       "16                                      The Crying Game\n",
       "17                                  The Hudsucker Proxy\n",
       "18                                           Spaceballs\n",
       "19                                          Poltergeist\n",
       "20                                              Tangled\n",
       "21                  Harry Potter and the Goblet of Fire\n",
       "22                             How to Train Your Dragon\n",
       "23                                         3:10 to Yuma\n",
       "24                                          First Blood\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return random maximum number of movies for each of 5 categories done by pca\n",
    "def get_movies_cold(): # 20 elements\n",
    "    return pd.concat([\n",
    "        get_sample(0,5),\n",
    "        get_sample(1,5),\n",
    "        get_sample(2,5),\n",
    "        get_sample(3,5),\n",
    "        get_sample(4,5),\n",
    "    ],ignore_index=True)\n",
    "\n",
    "get_movies_cold()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>movie_ix</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>tmdbId</th>\n",
       "      <th>genres</th>\n",
       "      <th>cover</th>\n",
       "      <th>title</th>\n",
       "      <th>full-title</th>\n",
       "      <th>year</th>\n",
       "      <th>director</th>\n",
       "      <th>producer</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>rating</th>\n",
       "      <th>category</th>\n",
       "      <th>cnt</th>\n",
       "      <th>small-cover</th>\n",
       "      <th>plot</th>\n",
       "      <th>length</th>\n",
       "      <th>youtubeId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_ix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>48780</td>\n",
       "      <td>1051</td>\n",
       "      <td>482571</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>Drama,Mystery,Sci-Fi,Thriller</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjA4ND...</td>\n",
       "      <td>The Prestige</td>\n",
       "      <td>The Prestige (2006)</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Touchstone Pictures</td>\n",
       "      <td>http://www.imdb.com/title/tt0482571/</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMjA4ND...</td>\n",
       "      <td>In the end of the Nineteenth Century, in Londo...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>a1AqrIkD7vU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movieId  movie_ix  imdbId  tmdbId                         genres  \\\n",
       "movie_ix                                                                     \n",
       "1051        48780      1051  482571  1124.0  Drama,Mystery,Sci-Fi,Thriller   \n",
       "\n",
       "                                                      cover         title  \\\n",
       "movie_ix                                                                    \n",
       "1051      https://m.media-amazon.com/images/M/MV5BMjA4ND...  The Prestige   \n",
       "\n",
       "                   full-title    year           director             producer  \\\n",
       "movie_ix                                                                        \n",
       "1051      The Prestige (2006)  2006.0  Christopher Nolan  Touchstone Pictures   \n",
       "\n",
       "                                      imdb_url  rating  category  cnt  \\\n",
       "movie_ix                                                                \n",
       "1051      http://www.imdb.com/title/tt0482571/     8.5         2   90   \n",
       "\n",
       "                                                small-cover  \\\n",
       "movie_ix                                                      \n",
       "1051      https://m.media-amazon.com/images/M/MV5BMjA4ND...   \n",
       "\n",
       "                                                       plot  length  \\\n",
       "movie_ix                                                              \n",
       "1051      In the end of the Nineteenth Century, in Londo...   130.0   \n",
       "\n",
       "            youtubeId  \n",
       "movie_ix               \n",
       "1051      a1AqrIkD7vU  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists = np.array([1,87,39,15,9,10,10]) # (kx1), movieId zaczyna od 1, czyli filtrujemy indexach macierzy\n",
    "#no_watch = np.array([3,8]) # (kx1), movieId zaczyna od 1, czyli filtrujemy indexach macierzy\n",
    "#to_watch = np.array([4,37]) # (kx1), movieId zaczyna od 1, czyli filtrujemy indexach macierzy\n",
    "\n",
    "# get movie replace except list in the \n",
    "def get_movie_replace(lists, n=1, head=100, min_cnt=20):\n",
    "    global movies\n",
    "    mask = movies['movie_ix'].isin(lists)\n",
    "    return movies[(~mask) & (movies['cnt']>min_cnt)].sort_values(by='rating',ascending=False).head(head).sample(n)\n",
    "\n",
    "\n",
    "get_movie_replace(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 19)\n",
      "      movie_ix                                              title\n",
      "id                                                               \n",
      "2            2                                               Heat\n",
      "26          26                                      Jurassic Park\n",
      "70          70                            Raiders of the Lost Ark\n",
      "74          74                                         Goodfellas\n",
      "103        103                                  L.A. Confidential\n",
      "165        165                Lock, Stock and Two Smoking Barrels\n",
      "192        192                                         Fight Club\n",
      "240        240                               Inglourious Basterds\n",
      "359        359                                 This Is Spinal Tap\n",
      "490        490                                             Casino\n",
      "752        752                                     Ocean's Eleven\n",
      "754        754                                   A Beautiful Mind\n",
      "1027      1027                                      The Godfather\n",
      "1104      1104                                    A Grand Day Out\n",
      "1134      1134                                           Die Hard\n",
      "1136      1136                             The Godfather: Part II\n",
      "1137      1137                                        Raging Bull\n",
      "1474      1474                                    Raising Arizona\n",
      "2078      2078                                           Das Boot\n",
      "2404      2404  The Fog of War: Eleven Lessons from the Life o...\n",
      "Wall time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## import pickle\n",
    "import torch\n",
    "\n",
    "np.random.seed(2) # to test\n",
    "\n",
    "def get_all_movies():\n",
    "    movies = pd.read_csv('../data/movie_input.csv');\n",
    "    movies.index = movies['movie_ix']\n",
    "    movies.index.name = 'id'\n",
    "    return movies\n",
    "\n",
    "movies = get_all_movies()\n",
    "y_range=[0.5,5.5]\n",
    "\n",
    "with open('../data/movie_recommendation.pickle', 'rb') as handle:\n",
    "    (matrix,\n",
    "     movies_weights,\n",
    "     movies_bias,\n",
    "     user_weights,\n",
    "     user_bias) = pickle.load(handle)\n",
    "\n",
    "def forward(users_w,users_b,movies_w,movies_b):\n",
    "    #print(users_w.shape,movies_w.shape)\n",
    "    dot = ((users_w@torch.t(movies_w)+users_b).squeeze()+torch.t(movies_b)).squeeze()\n",
    "    res = torch.sigmoid(dot)*(y_range[1]-y_range[0])+y_range[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_movies_recommendations(lists, to_watch=[], n = 20): #movie_ix, rating\n",
    "    global matrix, user_weights, user_bias, movies_bias,movies_weights, movies\n",
    "    \n",
    "    lists = np.array(sorted(lists, key=lambda a_entry: a_entry[0]))  #sortowanie po movieId\n",
    "    movie_ixs = lists[:,0]\n",
    "    movie_ratings=lists[:,1]\n",
    "    \n",
    "    # 2. filtrowanie po zaznaczonych listach, matrix zawiera już oceny dla wsystkich użytkowników\n",
    "    reduced_matrix=matrix[:,movie_ixs] \n",
    "    \n",
    "    # 3. Obliczamy pearson-a\n",
    "    from scipy.stats.stats import pearsonr\n",
    "    \n",
    "    pearsons = np.array([])\n",
    "    for ind, i in enumerate(reduced_matrix):\n",
    "        #print(i, pearsonr(movie_ratings,i.numpy()), pearsonr(movie_ratings,i.numpy())[0])\n",
    "        p_coeff=pearsonr(movie_ratings,i.numpy())[0]\n",
    "        pearsons=np.append(pearsons,p_coeff)\n",
    "    \n",
    "    # 4. Pobieramy top 10 użytkowników i jego macierze\n",
    "    top10_users=np.argsort(pearsons)[-10:]\n",
    "    reduced_users_matrix_weights=user_weights[top10_users] # 10x40\n",
    "    reduced_users_matrix_bias=user_bias[top10_users] # 10x1\n",
    "    # print(reduced_users_matrix_weights.shape,reduced_users_matrix_bias.shape)\n",
    "    \n",
    "    # 5. Obliczamy średnio wektor dla użytkownia\n",
    "    mean_vec_weights=reduced_users_matrix_weights.mean(0)[None] # 1x40\n",
    "    mean_vec_bias=reduced_users_matrix_bias.mean(0)[None]       # 1x1\n",
    "    \n",
    "    # 6. forward\n",
    "    result = forward(mean_vec_weights, mean_vec_bias, movies_weights, movies_bias)\n",
    "    #print(result)\n",
    "    #result = result[movies['movie_ix']]\n",
    "    \n",
    "    # 7. top 30 films, we will get 50 best movies and random sample , n = 20\n",
    "    # remove also muvies to watch\n",
    "    movie_ixs = np.append(movie_ixs,to_watch)\n",
    "    sample_size = (len(movie_ixs)+n)\n",
    "    size = sample_size+50\n",
    "    \n",
    "    # get only movies that has description in movies Dataframe    \n",
    "    tmp = np.array([],int)\n",
    "    for r in result.argsort(0,descending=True).numpy():\n",
    "        if r in movies['movie_ix']:\n",
    "            tmp = np.append(tmp, r)\n",
    "            if len(tmp)>=size: break\n",
    "    #print(tmp)\n",
    "    #print(result.argsort(0,desc))\n",
    "    #print(result.argsort(0,descending=True).numpy().isin(movies['movie_ix']))\n",
    "    \n",
    "    top40_films=tmp[np.random.choice(size,sample_size, replace=False)]\n",
    "    #print(top40_films, movies.loc[top40_films]['title'], result[result.argsort(0,descending=True)])\n",
    "    \n",
    "    # 8. get top 20 movies (n=20)\n",
    "    top20 = np.array([],int)\n",
    "    for ix in top40_films:\n",
    "        if len(top20)>=n: break\n",
    "        if ix not in movie_ixs:\n",
    "            top20=np.append(top20, ix)\n",
    "    \n",
    "    return  movies.loc[top20]\n",
    "    \n",
    "lists = np.array([[1,5],[875,2],[23,1],[13,3]]) # (kx1), movieId zaczyna od 1, czyli filtrujemy indexach macierzy, to test\n",
    "#lists = np.array([[1,5],[12,2],[23,1],[13,3]]) # (kx1), movieId zaczyna od 1, czyli filtrujemy indexach macierzy, to test\n",
    "#to_watch = np.array([166,335,248]) # this three movies are in the choose\n",
    "\n",
    "to_watch = np.array([166,335,248,25]) # this three movies are in the choose\n",
    "\n",
    "movies_filtered = get_movies_recommendations(lists, to_watch)\n",
    "\n",
    "print(movies_filtered.shape)\n",
    "print(movies_filtered[['movie_ix','title']].sort_values(by='movie_ix'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Movie_recommendation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
